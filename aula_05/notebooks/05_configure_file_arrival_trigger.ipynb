{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Configura√ß√£o de Trigger: File Arrival (Chegada de Arquivo)\n",
        "\n",
        "Este notebook demonstra como configurar um **Lakeflow Job** com trigger do tipo **File Arrival** para ingest√£o autom√°tica quando novos arquivos chegam no volume.\n",
        "\n",
        "## üìã Objetivo\n",
        "\n",
        "Criar um job que executa automaticamente a ingest√£o de `claims*.csv` sempre que um novo arquivo √© detectado no diret√≥rio `/Volumes/{catalog}/00_landing/sql_server/`.\n",
        "\n",
        "## üîÑ Fluxo do Trigger File Arrival\n",
        "\n",
        "1. **Monitoramento**: O Lakeflow Jobs monitora o diret√≥rio especificado\n",
        "2. **Detec√ß√£o**: Quando um novo arquivo `claims*.csv` √© adicionado ao volume\n",
        "3. **Disparo**: O job √© automaticamente executado\n",
        "4. **Processamento**: O script `ingestion_claim.py` processa todos os arquivos `claims*.csv`\n",
        "\n",
        "## üìù Pr√©-requisitos\n",
        "\n",
        "- ‚úÖ Cat√°logo e schemas criados\n",
        "- ‚úÖ Volume `00_landing` configurado\n",
        "- ‚úÖ Script `ingestion_claim.py` dispon√≠vel em `source_to_bronze/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Passo 1: Criar o Job no Lakeflow Jobs\n",
        "\n",
        "1. Acesse **Lakeflow Jobs** no menu lateral do Databricks\n",
        "2. Clique em **Create Job**\n",
        "3. Configure o nome: `ingestion_claims_file_arrival`\n",
        "4. Adicione uma **Task** do tipo **Python Script**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÇ Passo 2: Configurar a Task\n",
        "\n",
        "### Configura√ß√µes da Task:\n",
        "\n",
        "**Task Name:** `ingest_claims`\n",
        "\n",
        "**Task Type:** `Python script`\n",
        "\n",
        "**Source:** `Workspace file`\n",
        "- Caminho: `/Workspace/Users/{seu_usuario}/trilha_databricks/aula_05/source_to_bronze/ingestion_claim.py`\n",
        "- Ou use: `File path` e navegue at√© o arquivo\n",
        "\n",
        "**Parameters (Task Variables):**\n",
        "- `catalog` = `smart_claims_dev`\n",
        "- `schema` = `01_bronze`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Passo 3: Configurar o Trigger File Arrival\n",
        "\n",
        "### No painel de configura√ß√£o do Job:\n",
        "\n",
        "1. V√° para a se√ß√£o **Triggers**\n",
        "2. Clique em **Add trigger**\n",
        "3. Selecione **File arrival**\n",
        "\n",
        "### Configura√ß√µes do Trigger:\n",
        "\n",
        "**Trigger Type:** `File arrival`\n",
        "\n",
        "**Path to monitor:** \n",
        "```\n",
        "/Volumes/smart_claims_dev/00_landing/sql_server/\n",
        "```\n",
        "\n",
        "**File pattern:** \n",
        "```\n",
        "claims*.csv\n",
        "```\n",
        "\n",
        "**Wait for completion:** \n",
        "- ‚úÖ Marque esta op√ß√£o se quiser que o job aguarde a conclus√£o antes de processar novos arquivos\n",
        "- √ötil para evitar execu√ß√µes concorrentes\n",
        "\n",
        "**Min time between triggers (seconds):**\n",
        "- Exemplo: `60` (aguarda 60 segundos entre execu√ß√µes)\n",
        "- Evita m√∫ltiplas execu√ß√µes se v√°rios arquivos chegarem ao mesmo tempo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Passo 4: Testar o Trigger\n",
        "\n",
        "### Simular chegada de arquivo:\n",
        "\n",
        "Execute o c√≥digo abaixo para simular a adi√ß√£o de um novo arquivo no volume:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simular chegada de novo arquivo\n",
        "# Este c√≥digo cria um arquivo CSV de teste no volume\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "catalog = \"smart_claims_dev\"\n",
        "volume_path = f\"/Volumes/{catalog}/00_landing/sql_server/\"\n",
        "\n",
        "# Criar um arquivo de teste com timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "test_file = f\"{volume_path}claims_test_{timestamp}.csv\"\n",
        "\n",
        "# Exemplo de dados de teste\n",
        "test_data = \"\"\"claim_no,policy_no,claim_date,months_as_customer,injury,property,vehicle,total\n",
        "TEST001,POL001,2024-01-15,12,0,1000,5000,6000\"\"\"\n",
        "\n",
        "# Escrever arquivo (simula chegada de novo arquivo)\n",
        "with open(test_file, \"w\") as f:\n",
        "    f.write(test_data)\n",
        "\n",
        "print(f\"‚úÖ Arquivo de teste criado: {test_file}\")\n",
        "print(f\"üìä O job deve ser disparado automaticamente em alguns segundos!\")\n",
        "print(f\"üîç Verifique o status do job em: Lakeflow Jobs > ingestion_claims_file_arrival\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Passo 5: Monitorar Execu√ß√µes\n",
        "\n",
        "### Verificar execu√ß√µes do job:\n",
        "\n",
        "1. Acesse **Lakeflow Jobs** > `ingestion_claims_file_arrival`\n",
        "2. Veja o hist√≥rico de execu√ß√µes na aba **Runs**\n",
        "3. Cada execu√ß√£o mostra:\n",
        "   - **Trigger:** File arrival\n",
        "   - **Arquivo detectado:** Nome do arquivo que disparou o job\n",
        "   - **Status:** Success, Failed, ou Running\n",
        "   - **Tempo de execu√ß√£o**\n",
        "\n",
        "### Verificar logs:\n",
        "\n",
        "- Clique em uma execu√ß√£o para ver logs detalhados\n",
        "- Verifique se todos os arquivos `claims*.csv` foram processados\n",
        "- Confirme que a tabela `smart_claims_dev.01_bronze.claims` foi atualizada\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Vantagens do Trigger File Arrival\n",
        "\n",
        "- ‚úÖ **Automa√ß√£o completa**: N√£o precisa executar manualmente\n",
        "- ‚úÖ **Tempo real**: Processa dados assim que chegam\n",
        "- ‚úÖ **Efici√™ncia**: S√≥ executa quando h√° novos arquivos\n",
        "- ‚úÖ **Confiabilidade**: Evita perda de dados por atraso no processamento\n",
        "\n",
        "## ‚ö†Ô∏è Considera√ß√µes Importantes\n",
        "\n",
        "- O trigger monitora o diret√≥rio continuamente\n",
        "- M√∫ltiplos arquivos podem disparar m√∫ltiplas execu√ß√µes\n",
        "- Use `Min time between triggers` para evitar sobrecarga\n",
        "- O padr√£o glob `claims*.csv` processa TODOS os arquivos correspondentes a cada execu√ß√£o\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
