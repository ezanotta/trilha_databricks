{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Exemplos de Outros Tipos de Triggers\n",
        "\n",
        "Este notebook apresenta exemplos de configura√ß√£o para os outros tipos de triggers dispon√≠veis no Lakeflow Jobs.\n",
        "\n",
        "## üìã Tipos de Triggers Dispon√≠veis\n",
        "\n",
        "1. ‚úÖ **Time-based (Agendado)** - Executa em hor√°rios definidos\n",
        "2. ‚úÖ **Continuous (Cont√≠nuo)** - Execu√ß√£o constante, sempre ativa\n",
        "3. ‚úÖ **File Arrival** - Dispara quando novo arquivo √© detectado (ver notebook 05)\n",
        "4. ‚úÖ **Manual** - Iniciado pelo usu√°rio\n",
        "5. ‚úÖ **Table Update** - Executa quando h√° altera√ß√£o em tabela (ver notebook 06)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚è∞ Trigger 1: Time-based (Agendado)\n",
        "\n",
        "### Quando usar:\n",
        "- Processamento batch di√°rio, semanal ou mensal\n",
        "- Relat√≥rios agendados\n",
        "- Limpeza de dados peri√≥dica\n",
        "- Backup de tabelas\n",
        "\n",
        "### Configura√ß√£o:\n",
        "\n",
        "**Trigger Type:** `Scheduled`\n",
        "\n",
        "**Schedule:**\n",
        "- **Cron expression:** `0 0 2 * * ?` (todos os dias √†s 02:00)\n",
        "- **Timezone:** `America/Sao_Paulo`\n",
        "\n",
        "**Exemplos de Cron:**\n",
        "- `0 0 2 * * ?` - Di√°rio √†s 02:00\n",
        "- `0 0 0 ? * MON` - Toda segunda-feira √† meia-noite\n",
        "- `0 0 0 1 * ?` - Primeiro dia de cada m√™s\n",
        "- `0 */30 * * * ?` - A cada 30 minutos\n",
        "\n",
        "### Exemplo de Job:\n",
        "\n",
        "**Nome:** `daily_claims_ingestion`\n",
        "\n",
        "**Schedule:** `0 0 2 * * ?` (di√°rio √†s 02:00)\n",
        "\n",
        "**Task:** Executa `ingestion_claim.py` para reprocessar todos os dados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Trigger 2: Continuous (Cont√≠nuo)\n",
        "\n",
        "### Quando usar:\n",
        "- Processamento de streaming em tempo real\n",
        "- Monitoramento cont√≠nuo de dados\n",
        "- Pipelines que precisam estar sempre ativos\n",
        "- Processamento de eventos em tempo real\n",
        "\n",
        "### Configura√ß√£o:\n",
        "\n",
        "**Trigger Type:** `Continuous`\n",
        "\n",
        "**Restart on failure:**\n",
        "- ‚úÖ Marque para reiniciar automaticamente em caso de falha\n",
        "\n",
        "**Max concurrent runs:**\n",
        "- Exemplo: `1` (apenas uma execu√ß√£o por vez)\n",
        "- Evita sobrecarga do cluster\n",
        "\n",
        "### Exemplo de Job:\n",
        "\n",
        "**Nome:** `continuous_claims_streaming`\n",
        "\n",
        "**Trigger:** Continuous\n",
        "\n",
        "**Task:** Processa dados de streaming usando `readStream()` do Spark\n",
        "\n",
        "**‚ö†Ô∏è Aten√ß√£o:** Jobs cont√≠nuos consomem recursos constantemente. Use apenas quando necess√°rio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üë§ Trigger 3: Manual\n",
        "\n",
        "### Quando usar:\n",
        "- Testes e desenvolvimento\n",
        "- Execu√ß√µes sob demanda\n",
        "- Reprocessamento manual de dados\n",
        "- Valida√ß√£o de pipelines\n",
        "\n",
        "### Configura√ß√£o:\n",
        "\n",
        "**Trigger Type:** `Manual`\n",
        "\n",
        "- N√£o requer configura√ß√£o adicional\n",
        "- Job s√≥ executa quando iniciado manualmente pelo usu√°rio\n",
        "\n",
        "### Como executar:\n",
        "\n",
        "1. Acesse **Lakeflow Jobs** > Seu Job\n",
        "2. Clique em **Run now**\n",
        "3. Ou use a API do Databricks para executar programaticamente\n",
        "\n",
        "### Exemplo de Job:\n",
        "\n",
        "**Nome:** `manual_data_validation`\n",
        "\n",
        "**Trigger:** Manual\n",
        "\n",
        "**Task:** Executa valida√ß√µes e testes de qualidade de dados\n",
        "\n",
        "**Uso:** Executar manualmente ap√≥s mudan√ßas no c√≥digo ou schema\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Compara√ß√£o de Triggers\n",
        "\n",
        "| Trigger | Uso Ideal | Frequ√™ncia | Recursos |\n",
        "|---------|-----------|------------|----------|\n",
        "| **Time-based** | Processamento batch agendado | Peri√≥dico (hor√°rio fixo) | Baixo (executa apenas no hor√°rio) |\n",
        "| **Continuous** | Streaming em tempo real | Constante | Alto (sempre ativo) |\n",
        "| **File Arrival** | Ingest√£o quando arquivo chega | Event-driven | M√©dio (s√≥ quando h√° arquivo) |\n",
        "| **Table Update** | Pipeline reativo a mudan√ßas | Event-driven | M√©dio (s√≥ quando h√° mudan√ßa) |\n",
        "| **Manual** | Testes e execu√ß√µes sob demanda | Sob demanda | Baixo (apenas quando executado) |\n",
        "\n",
        "## üéØ Recomenda√ß√µes por Cen√°rio\n",
        "\n",
        "### Ingest√£o de Arquivos CSV\n",
        "- ‚úÖ **File Arrival** - Ideal para processar arquivos assim que chegam\n",
        "\n",
        "### Transforma√ß√£o Bronze ‚Üí Silver\n",
        "- ‚úÖ **Table Update** - Ideal para manter dados silver sincronizados\n",
        "\n",
        "### Relat√≥rios Di√°rios\n",
        "- ‚úÖ **Time-based** - Executa em hor√°rio fixo todos os dias\n",
        "\n",
        "### Streaming de Dados\n",
        "- ‚úÖ **Continuous** - Processa dados em tempo real continuamente\n",
        "\n",
        "### Desenvolvimento e Testes\n",
        "- ‚úÖ **Manual** - Permite controle total sobre quando executar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Combinando M√∫ltiplos Triggers\n",
        "\n",
        "Voc√™ pode configurar **m√∫ltiplos triggers** para o mesmo job:\n",
        "\n",
        "### Exemplo: Job com 2 Triggers\n",
        "\n",
        "**Job:** `flexible_claims_processing`\n",
        "\n",
        "**Trigger 1:** File Arrival\n",
        "- Monitora: `/Volumes/.../claims*.csv`\n",
        "- Processa automaticamente quando arquivo chega\n",
        "\n",
        "**Trigger 2:** Time-based\n",
        "- Schedule: `0 0 1 * * ?` (di√°rio √†s 01:00)\n",
        "- Reprocessa todos os dados diariamente\n",
        "\n",
        "**Resultado:** \n",
        "- Processamento autom√°tico quando arquivo chega (File Arrival)\n",
        "- Reprocessamento completo di√°rio (Time-based)\n",
        "- Garante que dados estejam sempre atualizados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo: Criar job programaticamente usando Databricks API\n",
        "# Este c√≥digo demonstra como criar um job com trigger via API\n",
        "\n",
        "import json\n",
        "\n",
        "# Configura√ß√£o do job com trigger Time-based\n",
        "job_config = {\n",
        "    \"name\": \"daily_claims_ingestion\",\n",
        "    \"tasks\": [\n",
        "        {\n",
        "            \"task_key\": \"ingest_claims\",\n",
        "            \"python_wheel_task\": {\n",
        "                \"package_name\": \"ingestion_claim\",\n",
        "                \"entry_point\": \"main\"\n",
        "            },\n",
        "            \"libraries\": [\n",
        "                {\n",
        "                    \"pypi\": {\n",
        "                        \"package\": \"pyspark\"\n",
        "                    }\n",
        "                }\n",
        "            ],\n",
        "            \"python_wheel_task\": {\n",
        "                \"parameters\": [\n",
        "                    \"--catalog\", \"smart_claims_dev\",\n",
        "                    \"--schema\", \"01_bronze\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "    \"schedule\": {\n",
        "        \"quartz_cron_expression\": \"0 0 2 * * ?\",\n",
        "        \"timezone_id\": \"America/Sao_Paulo\",\n",
        "        \"pause_status\": \"UNPAUSED\"\n",
        "    },\n",
        "    \"max_concurrent_runs\": 1,\n",
        "    \"timeout_seconds\": 3600\n",
        "}\n",
        "\n",
        "print(\"üìã Exemplo de configura√ß√£o de job com trigger Time-based:\")\n",
        "print(json.dumps(job_config, indent=2))\n",
        "\n",
        "# Para criar o job, use a API do Databricks:\n",
        "# POST /api/2.1/jobs/create\n",
        "# Headers: Authorization: Bearer <token>\n",
        "# Body: job_config (acima)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
